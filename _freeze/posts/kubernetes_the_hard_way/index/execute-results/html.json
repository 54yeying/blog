{
  "hash": "2750ee29cab7f42db31d20314b8461a2",
  "result": {
    "markdown": "---\ntitle: \"Kubernetes the hard way\"\nauthor: \"曳影\"\ndate: \"2022-11-19\"\ncategories: [kubernetes]\nformat:\n  html:\n    code-overflow: wrap\n---\n\n## 服务器说明\n### 节点要求\n- 节点数 >= 3台\n- CPUs  >= 2\n- Memory >= 2G\n\n### 网络配置\n- 节点之间任意端口都可以访问\n\n### 环境说明\n|系统类型|IP地址|节点角色|CPU|Memory|Hostname|\n|:-----:|:---:|:-----:|:--:|:---:|:------:|\n|CentOS-7.9|192.168.200.11|master|>=2|>=2G|node1|\n|CentOS-7.9|192.168.200.22|master,worker|>=2|>=2G|node2|\n|CentOS-7.9|192.168.200.33|worker|>=2|>=2G|node3|\n\n### 系统设置(所有节点)\n0. 所有操作需要`root`权限\n1. hostname (/etc/hosts)\n2. 安装依赖包\n\n\n```{shell}\ntouch 1.text\necho \"wwwwwwwww\"\n```\n\n\n```shell\nyum update -y\nyum install -y socat conntrack ipvsadm ipset jq sysstat curl iptables libseccomp yum-utils\n```\n3. 关闭防火墙,selinux, swap,重置 iptables\n\n```shell\n# 1. 关闭selinux\nsetenforce 0\nsed -i '/SELINUX/s/enforcing/disabled/' /etc/selinux/config\n# 2. 关闭防火墙\nsystemctl stop firewalld && systemctl disable firewalld\n\n# 3. 设置ipttables规则\niptables -F && iptables -X && iptables -F -t nat && iptables -X -t nat && iptables -P FORWARD ACCEPT\n\n# 4. 关闭swap\nvi /etc/fstab\n# 永久禁用注释掉swap\n#/swapfile none swap defaults 0 0\n# 临时禁用\nswapoff -a\n# 这里两者都用，临时修改可以即时生效，不用重启，永久禁用防止重启后不生效\n\n# 5. 关闭dnsmasq(否则无法解析域名)\nservice dnsmasq stop && systemctl disable dnsmasq\n```\n\n4. kubernetes参数设置\n\n```shell\ncat > /etc/sysctl.d/kubernetes.conf <<EOF\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.bridge.bridge-nf-call-iptables = 1\nnet.ipv4.ip_nonlocal_bind = 1\nnet.ipv4.ip_forward = 1\nvm.swappiness = 0\nvm.overcommit_memory = 1\nEOF\n\n# 生效文件\nsysctl -p /etc/sysctl.d/kubernetes.conf\n```\n\n5. 配置免密登录\n选择其中一个节点，或者一个单独的机器生成ssh公秘钥对，把公钥放在k8s所有节点服务器上\n\n```shell\n# 生成公秘钥对, 如果没有可用的\nssh-keygen -t rsa\n\n# 查看公钥内容\ncat ~/.ssh/id_rsa.pub\n\n# 放在其它机器上\necho \"<pubkey content>\" >> ~/.ssh/authorized_keys\n```\n\n6. 配置IP映射(每个节点)\n\n```shell\ncat > /etc/hosts <<EOF\n192.168.200.11 cluster1\n192.168.200.22 cluster2\n192.168.200.33 cluster3\nEOF\n```\n\n7. 下载k8s组件包\n\n```shell\nexport VERSION=v1.22.15\n\n# 下载master节点组件\nwget https://storage.googleapis.com/kubernetes-release/release/${VERSION}/bin/linux/amd64/kube-apiserver\nwget https://storage.googleapis.com/kubernetes-release/release/${VERSION}/bin/linux/amd64/kube-controller-manager\nwget https://storage.googleapis.com/kubernetes-release/release/${VERSION}/bin/linux/amd64/kube-scheduler\nwget https://storage.googleapis.com/kubernetes-release/release/${VERSION}/bin/linux/amd64/kubectl\n\n# 下载worker节点组件\nwget https://storage.googleapis.com/kubernetes-release/release/${VERSION}/bin/linux/amd64/kube-proxy\nwget https://storage.googleapis.com/kubernetes-release/release/${VERSION}/bin/linux/amd64/kubelet\n\n# 下载etcd组件\nwget https://github.com/etcd-io/etcd/releases/download/v3.4.10/etcd-v3.4.10-linux-amd64.tar.gz\ntar -xvf etcd-v3.4.10-linux-amd64.tar.gz\nmv etcd-v3.4.10-linux-amd64/etcd* .\nrm -fr etcd-v3.4.10-linux-amd64*\n```\n\n8. 分发软件包\n\n```shell\n# 把master相关组件分发到master节点\nMASTERS=(cluster1 cluster2)\nfor instance in ${MASTERS[@]}; do\n  scp kube-apiserver kube-controller-manager kube-scheduler kubectl root@${instance}:/usr/local/bin/\ndone\n\n# 把worker先关组件分发到worker节点\nWORKERS=(cluster2 cluster3)\nfor instance in ${WORKERS[@]}; do\n  scp kubelet kube-proxy root@${instance}:/usr/local/bin/\ndone\n\n# 把etcd组件分发到etcd节点\nETCDS=(cluster1 cluster2 cluster3)\nfor instance in ${ETCDS[@]}; do\n  scp etcd etcdctl root@${instance}:/usr/local/bin/\ndone\n```\n\n## kubernetes各组件的认证配置\nkubernetes的认证配置文件，称为`kubeconfigs`，用于让kubernetes的客户端定位\nkube-apiserver并通过apiserver的安全认证。\n\n+ controller-manager\n+ kubelet\n+ kube-proxy\n+ scheduler\n+ admin user\n\n## 为`kubelet`生成`kubeconfigs`(每个Worker节点)\n\n```shell\nWORKERS = (\"cluster2\" \"cluster3\")\nfor instance in ${WORKERS[@]}; do\n  kubectl config set-cluster kubernetes \\\n    --certificate-authority=ca.pem \\\n    --embed-certs=true \\\n    --server=https://127.0.0.1:6443 \\\n    --kubeconfig=${instance}.kubeconfig\n\n  kubectl config set-credentials system:node:${instance} \\\n    --client-certificate=${instance}.pem \\\n    --client-key=${instance}-key.pem \\\n    --embed-certs=true \\\n    --kubeconfig=${instance}.kubeconfig\n\n  kubectl config set-context default \\\n    --cluster=kubernetes \\\n    --user=system:node:${instance} \\\n    --kubeconfig=${instance}.kubeconfig\n\n  kubectl config use-context default --kubeconfig=${instance}.kubeconfig\ndone\n```\n\n### 为`kube-proxy`生成`kubeconfigs`\n\n```shell\nkubectl config set-cluster kubernetes \\\n    --certificate-authority=ca.pem \\\n    --embed-certs=true \\\n    --server=https://127.0.0.1:6443 \\\n    --kubeconfig=kube-proxy.kubeconfig\n\nkubectl config set-credentials system:kube-proxy \\\n   --client-certificate=kube-proxy.pem \\\n   --client-key=kube-proxy-key.pem \\\n   --embed-certs=true \\\n   --kubeconfig=kube-proxy.kubeconfig\n\nkubectl config set-context default \\\n   --cluster=kubernetes \\\n   --user=system:kube-proxy \\\n   --kubeconfig=kube-proxy.kubeconfig\n\nkubectl config use-context default --kubeconfig=kube-proxy.kubeconfig\n```\n\n### 为`kube-controller-manager`生成`kubeconfigs`\n\n```shell\nkubectl config set-cluster kubernetes \\\n  --certificate-authority=ca.pem \\\n  --embed-certs=true \\\n  --server=https://127.0.0.1:6443 \\\n  --kubeconfig=kube-controller-manager.kubeconfig\n\nkubectl config set-credentials system:kube-controller-manager \\\n  --client-certificate=kube-controller-manager.pem \\\n  --client-key=kube-controller-manager-key.pem \\\n  --embed-certs=true \\\n  --kubeconfig=kube-controller-manager.kubeconfig\n\nkubectl config set-context default \\\n  --cluster=kubernetes \\\n  --user=system:kube-controller-manager \\\n  --kubeconfig=kube-controller-manager.kubeconfig\n\nkubectl config use-context default --kubeconfig=kube-controller-manager.kubeconfig\n```\n\n### 为`kube-scheduler`生成`kubeconfigs`\n\n```shell\nkubectl config set-cluster kubernetes \\\n  --certificate-authority=ca.pem \\\n  --embed-certs=true \\\n  --server=https://127.0.0.1:6443 \\\n  --kubeconfig=kube-scheduler.kubeconfig\n\nkubectl config set-credentials system:kube-scheduler \\\n  --client-certificate=kube-scheduler.pem \\\n  --client-key=kube-scheduler-key.pem \\\n  --embed-certs=true \\\n  --kubeconfig=kube-scheduler.kubeconfig\n\nkubectl config set-context default \\\n  --cluster=kubernetes \\\n  --user=system:kube-scheduler \\\n  --kubeconfig=kube-scheduler.kubeconfig\n\nkubectl config use-context default --kubeconfig=kube-scheduler.kubeconfig\n```\n\n### 为`admin`用户生成`kubeconfigs`\n\n```shell\nkubectl config set-cluster kubernetes \\\n  --certificate-authority=ca.pem \\\n  --embed-certs=true \\\n  --server=https://127.0.0.1:6443 \\\n  --kubeconfig=admin.kubeconfig\n\nkubectl config set-credentials admin \\\n  --client-certificate=admin.pem \\\n  --client-key=admin-key.pem \\\n  --embed-certs=true \\\n  --kubeconfig=admin.kubeconfig\n\nkubectl config set-context default \\\n  --cluster=kubernetes \\\n  --user=admin \\\n  --kubeconfig=admin.kubeconfig\n\nkubectl config use-context default --kubeconfig=admin.kubeconfig\n```\n\n## 分发`kubeconfigs`配置文件\n### `kubelet`和`kube-proxy`的`kubeconfigs`分发到`Worker`节点\n\n```shell\nfor instance in ${WORKERS[@]}; do\n  scp ${instance}.kubeconfig kube-proxy.kubeconfig ${install}:~/\ndone\n```\n\n### `kube-controller-manager`和`kube-scheduler`的`kubeconfigs`分发到`Master`节点\n\n```shell\nMASTERS=(\"cluster1\" \"cluster3\")\nfor instance in ${MASTERS[@]}; do\n  scp admin.kubeconfig kube-controller-manager.kubeconfig kube-scheduler.kubeconfig ${instance}:~/\ndone\n```\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}